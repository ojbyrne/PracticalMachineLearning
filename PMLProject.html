<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Owen Byrne" />


<title>Practical Machine Learning Project: Human Activity Recognition</title>

<script src="PMLProject_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="PMLProject_files/bootstrap-2.3.2/css/bootstrap.min.css" rel="stylesheet" />
<link href="PMLProject_files/bootstrap-2.3.2/css/bootstrap-responsive.min.css" rel="stylesheet" />
<script src="PMLProject_files/bootstrap-2.3.2/js/bootstrap.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="PMLProject_files/highlight/default.css"
      type="text/css" />
<script src="PMLProject_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">Practical Machine Learning Project: Human Activity Recognition</h1>
<h4 class="author"><em>Owen Byrne</em></h4>
<h4 class="date"><em>December 6, 2014</em></h4>
</div>


<div id="executive-summary" class="section level1">
<h1>Executive Summary</h1>
<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts (including the author) who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.</p>
<p>The aim of this report was to use data from accelerometers placed on the belt, forearm, arm, and dumbell of six participants to predict how well they were doing the exercise in terms of the classification in the data.</p>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre class="r"><code>directory &lt;- &quot;data&quot;
training_file &lt;- &quot;training.csv&quot;
testing_file &lt;- &quot;testing.csv&quot;

if (!file.exists(directory)) {
    dir.create(directory)
}

# curl option needed on OSX to access https urls
download.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;, destfile = paste(&quot;./&quot;, directory, &quot;/&quot;, training_file, sep=&quot;&quot;), method=&quot;curl&quot;, quiet=TRUE)
download.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;, destfile = paste(&quot;./&quot;, directory, &quot;/&quot;, testing_file, sep=&quot;&quot;), method=&quot;curl&quot;, quiet=TRUE)</code></pre>
<p>Training data was read from the csv file, and some data cleaning was done. The first seven columns (data specific to each record, such as name, timestamps, etc) were removed. Columns that contained any NAs were also removed. This left a total of 59 columns + the “classe” column to be predicted.</p>
<pre class="r"><code>data_training &lt;- read.csv(paste(&quot;./&quot;, directory, &quot;/&quot;, training_file, sep=&quot;&quot;), na.strings= c(&quot;NA&quot;,&quot;&quot;,&quot; &quot;))
data_training_clean &lt;- data_training[8:length(data_training)]
data_training_NAs &lt;- apply(data_training_clean, 2, function(x) {sum(is.na(x))})
data_training_clean &lt;- data_training_clean[,which(data_training_NAs == 0)]
ncol(data_training_clean)</code></pre>
<pre><code>## [1] 53</code></pre>
<p>The cleaned data was then split into training and cross-validation sets.</p>
<pre class="r"><code>inTrain &lt;- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training &lt;- data_training_clean[inTrain, ]
validation &lt;- data_training_clean[-inTrain, ]</code></pre>
<p>A random forest model was selected first to predict the classification because it has methods for balancing error in class population unbalanced data sets. One downside is fitting the model was very slow. Because the random forest model was so slow, a second model using boosting was done.</p>
<p>The correlation between any two trees in the forest increases the forest error rate. Therefore, a correllation plot was produced in order to see how strong the variables relationships are with each other (Exhibit 1).</p>
<pre class="r"><code>system.time(model1 &lt;- train(classe ~ ., data=training, method=&quot;rf&quot;))</code></pre>
<pre><code>##     user   system  elapsed 
## 3438.048   25.039 3472.051</code></pre>
<pre class="r"><code>model1</code></pre>
<pre><code>## Random Forest 
## 
## 13737 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## 
## Summary of sample sizes: 13737, 13737, 13737, 13737, 13737, 13737, ... 
## 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
##    2    0.9892428  0.9863860  0.001784083  0.002257114
##   27    0.9893411  0.9865101  0.001886403  0.002391718
##   52    0.9810287  0.9759894  0.003886122  0.004923273
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 27.</code></pre>
<pre class="r"><code>system.time(model2 &lt;- train(classe ~ ., data=training, method=&quot;gbm&quot;, verbose=FALSE))</code></pre>
<pre><code>## Loading required package: gbm
## Loading required package: survival
## Loading required package: splines
## 
## Attaching package: &#39;survival&#39;
## 
## The following object is masked from &#39;package:caret&#39;:
## 
##     cluster
## 
## Loading required package: parallel
## Loaded gbm 2.1
## Loading required package: plyr</code></pre>
<pre><code>##     user   system  elapsed 
## 1339.970   15.943 1357.955</code></pre>
<pre class="r"><code>model2</code></pre>
<pre><code>## Stochastic Gradient Boosting 
## 
## 13737 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## 
## Summary of sample sizes: 13737, 13737, 13737, 13737, 13737, 13737, ... 
## 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  Accuracy   Kappa      Accuracy SD
##   1                   50      0.7493062  0.6820847  0.007023209
##   1                  100      0.8179979  0.7695604  0.006154225
##   1                  150      0.8514605  0.8119618  0.005892589
##   2                   50      0.8538849  0.8148161  0.005445105
##   2                  100      0.9047964  0.8794855  0.003947646
##   2                  150      0.9279250  0.9087760  0.003780551
##   3                   50      0.8938650  0.8655848  0.005250992
##   3                  100      0.9385747  0.9222521  0.003477489
##   3                  150      0.9578890  0.9467054  0.002556781
##   Kappa SD   
##   0.008898496
##   0.007807239
##   0.007412780
##   0.006834059
##   0.004951233
##   0.004743249
##   0.006609288
##   0.004386199
##   0.003218329
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## Accuracy was used to select the optimal model using  the largest value.
## The final values used for the model were n.trees = 150,
##  interaction.depth = 3 and shrinkage = 0.1.</code></pre>
<div id="cross-validation" class="section level2">
<h2>Cross-validation</h2>
<p>the validation set was then predicted with the 2 models, and a confusion matrix produced, showing a very high accuracy (99.81%) for random forests, and a slightly lower accuracy for boosting.</p>
<pre class="r"><code>predictRFCrossVal1 &lt;- predict(model1, validation)
confusionMatrix(validation$classe, predictRFCrossVal1)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1668    5    0    0    1
##          B    7 1126    6    0    0
##          C    0    9 1014    3    0
##          D    0    0   23  941    0
##          E    0    0    1    3 1078
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9901          
##                  95% CI : (0.9873, 0.9925)
##     No Information Rate : 0.2846          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9875          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9958   0.9877   0.9713   0.9937   0.9991
## Specificity            0.9986   0.9973   0.9975   0.9953   0.9992
## Pos Pred Value         0.9964   0.9886   0.9883   0.9761   0.9963
## Neg Pred Value         0.9983   0.9971   0.9938   0.9988   0.9998
## Prevalence             0.2846   0.1937   0.1774   0.1609   0.1833
## Detection Rate         0.2834   0.1913   0.1723   0.1599   0.1832
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9972   0.9925   0.9844   0.9945   0.9991</code></pre>
<pre class="r"><code>predictRFCrossVal2 &lt;- predict(model2, validation)
confusionMatrix(validation$classe, predictRFCrossVal2)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1648   22    4    0    0
##          B   40 1060   37    0    2
##          C    0   36  977   11    2
##          D    1    4   38  914    7
##          E    2   15   14   18 1033
## 
## Overall Statistics
##                                          
##                Accuracy : 0.957          
##                  95% CI : (0.9515, 0.962)
##     No Information Rate : 0.2873         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9456         
##  Mcnemar&#39;s Test P-Value : 3.299e-08      
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9746   0.9323   0.9131   0.9692   0.9895
## Specificity            0.9938   0.9834   0.9898   0.9899   0.9899
## Pos Pred Value         0.9845   0.9306   0.9522   0.9481   0.9547
## Neg Pred Value         0.9898   0.9838   0.9809   0.9941   0.9977
## Prevalence             0.2873   0.1932   0.1818   0.1602   0.1774
## Detection Rate         0.2800   0.1801   0.1660   0.1553   0.1755
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9842   0.9578   0.9515   0.9796   0.9897</code></pre>
</div>
<div id="predictions" class="section level2">
<h2>Predictions</h2>
<p>Finally, the testing set was loaded into R, the same cleaning was done, and the two models applied to classify the test set.</p>
<pre class="r"><code># apply the same treatment to the final testing data
data_test &lt;- read.csv(paste(&quot;./&quot;, directory, &quot;/&quot;, testing_file, sep=&quot;&quot;), na.strings= c(&quot;NA&quot;,&quot;&quot;,&quot; &quot;))
data_test_NAs &lt;- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean &lt;- data_test[,which(data_test_NAs == 0)]
data_test_clean &lt;- data_test_clean[8:length(data_test_clean)]

# predict the classes of the test set
answers1 &lt;- predict(model1, data_test_clean)
answers1</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
<pre class="r"><code>answers2 &lt;- predict(model2, data_test_clean)
answers2</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Both random forest and boosting provided excellent accuracy. Boosting was a little faster and slightly less accurate. Both methods scored perfectly on the testing set.</p>
<hr />
</div>
</div>
<div id="exhibit-1" class="section level1">
<h1>Exhibit 1</h1>
<pre class="r"><code>correlMatrix &lt;- cor(training[, -length(training)])
corrplot(correlMatrix, order = &quot;FPC&quot;, method = &quot;circle&quot;, type = &quot;lower&quot;, tl.cex = 0.8,  tl.col = rgb(0, 0, 0))</code></pre>
<p><img src="PMLProject_files/figure-html/unnamed-chunk-8-1.png" title="" alt="" width="768" /></p>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
