<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Owen Byrne" />


<title>Practical Machine Learning Project: Human Activity Recognition</title>

<script src="PMLProject_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="PMLProject_files/bootstrap-2.3.2/css/bootstrap.min.css" rel="stylesheet" />
<link href="PMLProject_files/bootstrap-2.3.2/css/bootstrap-responsive.min.css" rel="stylesheet" />
<script src="PMLProject_files/bootstrap-2.3.2/js/bootstrap.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="PMLProject_files/highlight/default.css"
      type="text/css" />
<script src="PMLProject_files/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">Practical Machine Learning Project: Human Activity Recognition</h1>
<h4 class="author"><em>Owen Byrne</em></h4>
<h4 class="date"><em>December 6, 2014</em></h4>
</div>


<div id="executive-summary" class="section level1">
<h1>Executive Summary</h1>
<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts (including the author) who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.</p>
<p>The aim of this report was to use data from accelerometers placed on the belt, forearm, arm, and dumbell of six participants to predict how well they were doing the exercise in terms of the classification in the data.</p>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre class="r"><code>directory &lt;- &quot;data&quot;
training_file &lt;- &quot;training.csv&quot;
testing_file &lt;- &quot;testing.csv&quot;

if (!file.exists(directory)) {
    dir.create(directory)
}

# curl option needed on OSX to access https urls
download.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;, destfile = paste(&quot;./&quot;, directory, &quot;/&quot;, training_file, sep=&quot;&quot;), method=&quot;curl&quot;, quiet=TRUE)
download.file(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;, destfile = paste(&quot;./&quot;, directory, &quot;/&quot;, testing_file, sep=&quot;&quot;), method=&quot;curl&quot;, quiet=TRUE)</code></pre>
<p>Training data was read from the csv file, and some data cleaning was done. The first seven columns (data specific to each record, such as name, timestamps, etc) were removed. Columns that contained any NAs were also removed. This left a total of 52 columns + the “classe” column to be predicted.</p>
<pre class="r"><code>data_training &lt;- read.csv(paste(&quot;./&quot;, directory, &quot;/&quot;, training_file, sep=&quot;&quot;), na.strings= c(&quot;NA&quot;,&quot;&quot;,&quot; &quot;))
data_training_clean &lt;- data_training[8:length(data_training)]
data_training_NAs &lt;- apply(data_training_clean, 2, function(x) {sum(is.na(x))})
data_training_clean &lt;- data_training_clean[,which(data_training_NAs == 0)]
ncol(data_training_clean)</code></pre>
<pre><code>## [1] 53</code></pre>
<p>The cleaned data was then split into training and cross-validation sets.</p>
<pre class="r"><code>inTrain &lt;- createDataPartition(y = data_training_clean$classe, p = 0.7, list = FALSE)
training &lt;- data_training_clean[inTrain, ]
validation &lt;- data_training_clean[-inTrain, ]</code></pre>
<p>A random forest model was selected first because it is purported to have high accuracy. One downside is fitting the model was very slow. Because the random forest model was so slow, a second model using boosting was also performed.</p>
<p>The correlation between any two trees in the forest increases the forest error rate. Therefore, a correllation plot was produced in order to see how strong the variables relationships are with each other (Exhibit 1).</p>
<pre class="r"><code>system.time(model1 &lt;- train(classe ~ ., data=training, method=&quot;rf&quot;))</code></pre>
<pre><code>##     user   system  elapsed 
## 3340.019   21.569 3366.086</code></pre>
<pre class="r"><code>model1</code></pre>
<pre><code>## Random Forest 
## 
## 13737 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## 
## Summary of sample sizes: 13737, 13737, 13737, 13737, 13737, 13737, ... 
## 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa      Accuracy SD  Kappa SD   
##    2    0.9879224  0.9847166  0.001977812  0.002503508
##   27    0.9882109  0.9850835  0.002154287  0.002721451
##   52    0.9814041  0.9764711  0.004311808  0.005448516
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 27.</code></pre>
<pre class="r"><code>system.time(model2 &lt;- train(classe ~ ., data=training, method=&quot;gbm&quot;, verbose=FALSE))</code></pre>
<pre><code>## Loading required package: gbm
## Loading required package: survival
## Loading required package: splines
## 
## Attaching package: &#39;survival&#39;
## 
## The following object is masked from &#39;package:caret&#39;:
## 
##     cluster
## 
## Loading required package: parallel
## Loaded gbm 2.1
## Loading required package: plyr</code></pre>
<pre><code>##     user   system  elapsed 
## 1336.494   14.833 1352.783</code></pre>
<pre class="r"><code>model2</code></pre>
<pre><code>## Stochastic Gradient Boosting 
## 
## 13737 samples
##    52 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## 
## Summary of sample sizes: 13737, 13737, 13737, 13737, 13737, 13737, ... 
## 
## Resampling results across tuning parameters:
## 
##   interaction.depth  n.trees  Accuracy   Kappa      Accuracy SD
##   1                   50      0.7503517  0.6835541  0.006726570
##   1                  100      0.8151943  0.7660454  0.005944192
##   1                  150      0.8503259  0.8105046  0.005661013
##   2                   50      0.8525829  0.8131998  0.005188758
##   2                  100      0.9042472  0.8788121  0.004118081
##   2                  150      0.9288520  0.9099607  0.003725185
##   3                   50      0.8945638  0.8664916  0.004830250
##   3                  100      0.9393041  0.9231858  0.003906556
##   3                  150      0.9573477  0.9460316  0.003653463
##   Kappa SD   
##   0.008408959
##   0.007528800
##   0.007169908
##   0.006586873
##   0.005193997
##   0.004700879
##   0.006133477
##   0.004956224
##   0.004618343
## 
## Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1
## Accuracy was used to select the optimal model using  the largest value.
## The final values used for the model were n.trees = 150,
##  interaction.depth = 3 and shrinkage = 0.1.</code></pre>
<div id="cross-validation" class="section level2">
<h2>Cross-validation</h2>
<p>The validation set was then predicted with the 2 models, and a confusion matrix produced, showing a very high accuracy (99.81%) for random forests, and a slightly lower accuracy (96.47%) for boosting. So the out of sample error is very low for either model.The random forest model took about 56 minutes to train, the boosting model only 24 minutes.</p>
<pre class="r"><code>predictRFCrossVal1 &lt;- predict(model1, validation)
confusionMatrix(validation$classe, predictRFCrossVal1)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1673    0    0    0    1
##          B    4 1134    1    0    0
##          C    0    6 1019    1    0
##          D    0    0   10  954    0
##          E    0    0    1    2 1079
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9956          
##                  95% CI : (0.9935, 0.9971)
##     No Information Rate : 0.285           
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9944          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9976   0.9947   0.9884   0.9969   0.9991
## Specificity            0.9998   0.9989   0.9986   0.9980   0.9994
## Pos Pred Value         0.9994   0.9956   0.9932   0.9896   0.9972
## Neg Pred Value         0.9991   0.9987   0.9975   0.9994   0.9998
## Prevalence             0.2850   0.1937   0.1752   0.1626   0.1835
## Detection Rate         0.2843   0.1927   0.1732   0.1621   0.1833
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9987   0.9968   0.9935   0.9974   0.9992</code></pre>
<pre class="r"><code>predictRFCrossVal2 &lt;- predict(model2, validation)
confusionMatrix(validation$classe, predictRFCrossVal2)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1650   13    5    5    1
##          B   42 1065   26    4    2
##          C    0   35  979    9    3
##          D    0    0   26  928   10
##          E    1   15    8   16 1042
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9624          
##                  95% CI : (0.9573, 0.9672)
##     No Information Rate : 0.2877          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9525          
##  Mcnemar&#39;s Test P-Value : 9.32e-08        
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9746   0.9441   0.9377   0.9647   0.9849
## Specificity            0.9943   0.9844   0.9903   0.9927   0.9917
## Pos Pred Value         0.9857   0.9350   0.9542   0.9627   0.9630
## Neg Pred Value         0.9898   0.9867   0.9866   0.9931   0.9967
## Prevalence             0.2877   0.1917   0.1774   0.1635   0.1798
## Detection Rate         0.2804   0.1810   0.1664   0.1577   0.1771
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9844   0.9643   0.9640   0.9787   0.9883</code></pre>
</div>
<div id="predictions" class="section level2">
<h2>Predictions</h2>
<p>Finally, the testing set was loaded into R, the same cleaning was done, and the two models applied to classify the test set.</p>
<pre class="r"><code># apply the same treatment to the final testing data
data_test &lt;- read.csv(paste(&quot;./&quot;, directory, &quot;/&quot;, testing_file, sep=&quot;&quot;), na.strings= c(&quot;NA&quot;,&quot;&quot;,&quot; &quot;))
data_test_NAs &lt;- apply(data_test, 2, function(x) {sum(is.na(x))})
data_test_clean &lt;- data_test[,which(data_test_NAs == 0)]
data_test_clean &lt;- data_test_clean[8:length(data_test_clean)]

# predict the classes of the test set
answers1 &lt;- predict(model1, data_test_clean)
answers1</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
<pre class="r"><code>answers2 &lt;- predict(model2, data_test_clean)
answers2</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Both random forest and boosting provided excellent accuracy. Boosting was a little faster and slightly less accurate. Both methods scored perfectly on the testing set.</p>
<hr />
</div>
</div>
<div id="exhibit-1" class="section level1">
<h1>Exhibit 1</h1>
<pre class="r"><code>correlMatrix &lt;- cor(training[, -length(training)])
corrplot(correlMatrix, order = &quot;FPC&quot;, method = &quot;circle&quot;, type = &quot;lower&quot;, tl.cex = 0.8,  tl.col = rgb(0, 0, 0))</code></pre>
<p><img src="PMLProject_files/figure-html/unnamed-chunk-8-1.png" title="" alt="" width="768" /></p>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
